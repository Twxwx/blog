---
title: 面试题
date: 2024-07-29 20:51:04
categories:
    - 面试相关
tags:
---

## 分类任务为什么不用均方误差而使用交叉熵？

1. MSE适用于线性回归，计算预测值和目标值的欧式距离。而交叉熵能够衡量同一个随机变量中的两个不同概率分布的差异程度，在机器学习中就表示为真实概率分布与预测概率分布之间的差异。交叉熵本质上是概率问题，表征真实概率分布与预测概率分布差异，和几何上的欧氏距离无关，在线性回归中才有欧氏距离的说法，在分类问题中label的值大小在欧氏空间中是没有意义的。所以分类问题不能用mse作为损失函数。

2. 分类问题会有激活函数这个非线性单元（sigmoid），如果使用 MSE 做损失函数的话计算结果是非凸函数，有多个极值点，不适用做损失函数。并且sigmoid函数和MSE一起使用时会出现梯度消失。

## 欠拟合和过拟合产生的原因和解决方法

### 欠拟合

#### 定义
- 欠拟合是指模型在训练数据和测试数据上都表现较差的现象。欠拟合的模型过于简单，以至于它无法捕捉到数据中的关键特征和模式

#### 原因
1. 模型过于简单，无法捕捉到数据中的关键特征和模式。
2. 选取的特征无法反映数据的真实分布，导致模型性能较差。

#### 解决方法
1. 选择更复杂的模型，增加模型参数的数量，使模型能够捕捉到数据中的关键特征和模式。
2. 通过特征选择、特征提取、特征组合等方法，选取有助于模型预测的特征，提升模型性能。
3. 通过调整学习率、批量大小、迭代次数等超参数，优化模型的训练过程，提升模型性能。

### 过拟合

#### 定义
- 过拟合是指模型在训练数据上表现良好，但在测试数据或新数据上表现较差的现象。过拟合的模型过于复杂，以至于它能够“记住”训练数据中的噪声，而非真实的数据分布。

#### 原因
1. 模型参数过多，过于复杂，容易导致模型过度拟合训练数据中的噪声。
2. 数据量不足以支持复杂数学公式，容易导致模型过拟合。
3. 数据噪声较大，模型可能学习到数据中的噪声，而非真实的数据分布。

#### 解决方法
1. 通过增加训练数据量，可以减小模型对噪声的敏感度，提升模型的泛化能力
2. 选择更简单的模型，减少模型参数的数量，避免模型过度拟合训练数据
3. 通过L1正则化、L2正则化等方法，限制模型参数的大小，防止模型过拟合
4. 在训练过程中，当验证集的损失不再显著下降时，提前停止训练，避免模型过拟合
5. 通过对训练数据进行旋转、翻转、缩放等数据增强操作，增加数据的多样性，提升模型的泛化能力

## 梯度消失和梯度爆炸产生的原因和解决方法

### 梯度消失

#### 定义

- 梯度消失问题主要出现在深层神经网络中，由于权重的累积，梯度在传播过程中会逐渐趋于零，导致模型无法学习到有效的梯度信息

#### 原因
1. 在深层网络中，不同层的学习速度差异很大
2. 采用了不合适的损失函数，比如sigmoid。反向传播时，每一层都要乘以激活函数的导数，sigmoid的导数会导致梯度不断衰减

### 梯度爆炸

#### 定义

- 梯度爆炸问题是指在某些情况下，梯度在传播过程中会逐渐增大，导致梯度计算过大，导致梯度下降算法不稳定或崩溃

#### 原因

1. 在深层网络中，不同层的学习速度差异很大
2. 权值初始化值太大

### 解决方法

1. 梯度剪切主要针对梯度爆炸，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。

2. 采用权重正则化（weithts regularization），正则化主要是通过对网络权重做正则来限制过拟合。如果发生梯度爆炸，那么权值就会变的非常大，反过来，通过正则化项来限制权重的大小，也可以在一定程度上防止梯度爆炸的发生。

3. 选择relu等梯度大部分落在常数上的激活函数

4.  batch normalization 通过对每一层的输出规范为均值和方差一致的方法，消除了权重参数放大缩小带来的影响，进而解决梯度消失和爆炸的问题

5. 使用残差网络