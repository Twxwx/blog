---
title: XGB模型
date: 2024-05-26 21:25:27
categories:
    - 机器学习
tags:
---

## 简介

- XGBoost是一个可扩展机器学习系统。严格意义上讲XGBoost并不是一种模型，而是一个可供用户轻松解决分类、回归或排序问题的软件包。它内部实现了梯度提升树(GBDT)模型，并对模型中的算法进行了诸多优化，在取得高精度的同时又保持了极快的速度。

- XGBoost在机器学习与数据挖掘领域有着极为广泛的应用，还被成功应用在工业界与学术界的各种问题中。例如商店销售额预测、高能物理事件分类、web文本分类;用户行为预测、运动检测、广告点击率预测、恶意软件分类、灾害风险预测、在线课程退学率预测。

## 优点

- 简单易用。相对其他机器学习库，用户可以轻松使用XGBoost并获得相当不错的效果。
- 高效可扩展。在处理大规模数据集时速度快效果好，对内存等硬件资源要求不高。
- 鲁棒性强。相对于深度学习模型不需要精细调参便能取得接近的效果。
- XGBoost内部实现提升树模型，可以自动处理缺失值。

## 缺点

- 相对于深度学习模型无法对时空位置建模，不能很好地捕获图像、语音、文本等高维数据。
- 在拥有海量训练数据，并能找到合适的深度学习模型时，深度学习的精度可以遥遥领先XGBoost。

## 原理

1. 梯度提升决策树（GBDT）

    - GBDT是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力较强的算法。GBDT中的树是回归树（不是分类树），GBDT用来做回归预测，调整后也可以用于分类。

2. XGBoost

    - XGBoost 是基于 CART 树的集成模型，它的思想是串联多个决策树模型共同进行决策。那么如何串联呢？XGBoost采用迭代预测误差的方法串联。举个通俗的例子，我们现在需要预测一辆车价值3000元。我们构建决策树1训练后预测为2600元，我们发现有400元的误差，那么决策树2的训练目标为400元，但决策树2的预测结果为350元，还存在50元的误差就交给第三棵树……以此类推，每一颗树用来估计之前所有树的误差，最后所有树预测结果的求和就是最终预测结果！

    ![](/img/note/202406071934.png)

## 训练

1. 特征构建

    - 对非数值进行编码。由于XGBoost无法处理字符串类型的数据，我们需要一些方法将字符串数据转化为数值。一种最简单的方法是把所有的相同类别的特征编码成同一个值，例如女=0，男=1，狗狗=2。除此之外，还有独热编码、求和编码、留一法编码等等方法可以获得更好的效果。

2. 特征重要性

    - 还可以利用 XGBoost 确定重要特征

3. 参数优化

    - 可以对参数进行调整优化
