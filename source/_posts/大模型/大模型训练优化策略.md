---
title: 大模型训练优化策略
date: 2024-02-19 23:49:45
categories:
    - 大模型
tags:
---

## GPU 显存分析

![](/img/note/202402232226.png)

![](/img/note/202402232227.png)


## Collective Operations

- Broadcast：将一个节点上的数据广播到集群内所有的节点

![](/img/note/202402232228.png)

- Scatter： 将数据的进行切片再分发给集群内所有的节点

![](/img/note/202402232232.png)

- Gather：可以在集群内把多个节点的数据收集到一个节点上

![](/img/note/202402232233.png)

- Reduce：在集群内把多个节点的数据规约运算到一个主节点上，规约操作例如求和、取最大值或取最小值等

![](/img/note/202402232230.png)

- AllReduce：其在集群内的所有节点上都执行相同的Reduce操作，可以将集群内所有节点的数据规约运算得到的结果发送到所有的节点上

![](/img/note/202402232229.png)

- ReduceScatter：将所有的节点上的数据先规约（比如SUM求和）到1个节点上，再进行分片scatter到集群内的所有节点上

![](/img/note/202402232231.png)

- AllGather：把多个节点的数据收集到一个主节点上（Gather），再把这个收集到的数据分发到其他节点上（broadcast），即收集集群内所有的数据到所有的节点上

![](/img/note/202402232234.png)

## 混合精度

![](/img/note/202402252248.png)


## Checkpointing

- 由于模型反向传播需要中间结果计算梯度，大量中间结果占用大量显存。
- Checkpointing 思路是保存部分隐藏层的结果（作为检查点），其余的中间结果直接释放。当反向传播需要计算梯度时，从检查点开始重新前向传播计算中间结果，得到梯度后再次释放。

## ZeRO（Zero Redundancy Optimizer）

- 零冗余优化器是一种用于大规模分布式深度学习的新型内存优化技术。在普通的数据并行策略中，每个 GPU 都独立地维护一组完整的模型参数，计算与通信效率较高，但内存效率较差。这个问题在训练大型模型时尤为突出。ZeRO 可以有效地减少显存消耗量，这意味着在同样的显存下，可以训练更大的模型。

### Adam 参数分析

![](/img/note/202402282044.png)

### 显存分析

- 训练深度学习模型时的显存消耗可以分为两大部分：

    1. 模型状态(model states)。对于大型模型来说，大部分显存消耗都是被模型状态占用的，主要包括三部分：优化器的状态(Optimizer States)、梯度(Gradients)、参数(Parameters)。三者简称为 OPG。
    2. 残余状态(residual states)。剩余状态（residual states）: 除了模型状态之外的显存占用，包括激活值（activation）、各种临时缓冲区（buffer）以及无法使用的显存碎片（fragmentation）

### ZeRO优化阶段

- ZeRO分为三个阶段，分别对应 O、P 和 G。每个 GPU 仅保存部分 OPG，三个阶段逐级递加：

![](/img/note/202402282045.png)

![](/img/note/202402282046.png)


