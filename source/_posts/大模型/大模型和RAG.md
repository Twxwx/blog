---
title: 大模型和RAG
date: 2024-02-01 17:47:51
categories:
    - 大模型
tags:
---

## 概述

- RAG（Retrieval Augmented Generation, 检索增强生成），即 LLM 在回答问题或生成文本时，先会从大量文档中检索出相关的信息，然后基于这些信息生成回答或文本，从而提高预测质量。RAG 方法使得开发者不必为每一个特定的任务重新训练整个大模型，只需要外挂上知识库，即可为模型提供额外的信息输入，提高其回答的准确性。RAG模型尤其适合知识密集型的任务。

![](/img/note/202403072241.png)

- 在 LLM 已经具备了较强能力的基础上，仍然需要 RAG ，主要有以下几点原因：

    - 幻觉问题：LLM 文本生成的底层原理是基于概率的 token by token 的形式，因此会不可避免地产生一本正经的胡说八道的情况。
    - 时效性问题：LLM 的规模越大，大模型训练的成本越高，周期也就越长。那么具有时效性的数据也就无法参与训练，所以也就无法直接回答时效性相关的问题。
    - 数据安全问题：通用的 LLM 没有企业内部数据和用户数据，那么企业想要在保证安全的前提下使用 LLM，最好的方式就是把数据全部放在本地，企业数据的业务计算全部在本地完成。而在线的大模型仅仅完成一个归纳的功能。

## RAG vs SFT

![](/img/note/202403072242.png)

- RAG 具有的优点：
    - 可扩展性 (Scalability)：减少模型大小和训练成本，并允许轻松扩展知识
    - 准确性 (Accuracy)：模型基于事实并减少幻觉
    - 可控性 (Controllability)：允许更新或定制知识
    - 可解释性 (Interpretability)：检索到的项目作为模型预测中来源的参考
    - 多功能性 (Versatility)：RAG 可以针对多种任务进行微调和定制，包括QA、文本摘要、对话系统等。

## RAG 典型实现方法

- RAG 的实现主要包括三个主要步骤：数据索引、检索和生成

![](/img/note/202403072243.png)

### 数据索引的构建

- 该部分主要功能是将原始数据处理成为便于检索的格式（通常为embedding）

1. 数据提取

    - 数据获取：获得作为知识库的多种格式的数据，包括PDF、word、markdown以及数据库和API等；
    - 数据清洗：对源数据进行去重、过滤、压缩和格式化等处理；
    - 信息提取：提取重要信息，包括文件名、时间、章节title、图片等信息。

2. 分块

    - 固定大小的分块方式：一般是256/512个tokens，取决于embedding模型的情况，弊端是会损失很多语义。
    - 句分割：最简单的是通过句号和换行来做切分，常用的意图包有基于NLP的NLTK和spaCy；
    - 递归分割：通过分而治之的思想，用递归切分到最小单元的一种方式；
    - 特殊分割：用于特殊场景。

3. 向量化（embedding）及创建索引

    - 即将文本、图像、音频和视频等转化为向量矩阵的过程，也就是变成计算机可以理解的格式
    - 生成 embedding 之后就是创建索引。最常见的即使用 FAISS 库创建向量搜索索引。

### 检索（Retrieval）

- 检索环节是获取有效信息的关键环节。检索优化一般分为下面五部分工作：

- 元数据过滤：当我们把索引分成许多chunks的时候，检索效率会成为问题。这时候，如果可以通过元数据先进行过滤，就会大大提升效率和相关度。
- 图关系检索：即引入知识图谱，将实体变成node，把它们之间的关系变成relation，就可以利用知识之间的关系做更准确的回答。特别是针对一些多跳问题，利用图数据索引会让检索的相关度变得更高；
- 检索技术：检索的主要方式还是这几种：
    - 相似度检索：包括欧氏距离、曼哈顿距离、余弦等；
    - 关键词检索：这是很传统的检索方式，元数据过滤也是一种，还有一种就是先把chunk做摘要，再通过关键词检索找到可能相关的chunk，增加检索效率。
    - SQL检索：更加传统的检索算法。
- 重排序（Rerank）：相关度、匹配度等因素做一些重新调整，得到更符合业务场景的排序。
- 查询轮换：这是查询检索的一种方式，一般会有几种方式：
    - 子查询：可以在不同的场景中使用各种查询策略，比如可以使用LlamaIndex等框架提供的查询器，采用树查询（从叶子结点，一步步查询，合并），采用向量查询，或者最原始的顺序查询chunks等；
    - HyDE：这是一种抄作业的方式，生成相似的或者更标准的 prompt 模板。

### 文本生成

- 文本生成就是将原始 query 和检索得到的文本组合起来输入模型得到结果的过程，本质上就是个 prompt engineering 过程

## Self-RAG 

- 前文所述的 RAG 方法都遵循着共同的范式，即：query + context -> LLM ，其中 query 表示用户的输入，context 表示检索获得的补充信息，然后共同输入到 LLM 中，可以认为这是一种检索前置的被动的增强方式。

- 相比而言，Self-RAG 则是更加主动和智能的实现方式，主要步骤概括如下：

    1. 判断是否需要额外检索事实性信息（retrieve on demand），仅当有需要时才召回
    2. 平行处理每个片段：生成 prompt + 一个片段的生成结果
    3. 使用反思字段，检查输出是否相关，选择最符合需要的片段；
    4. 再重复检索
    5. 生成结果会引用相关片段，以及输出结果是否符合该片段，便于查证事实。

![](/img/note/202403072244.png)
