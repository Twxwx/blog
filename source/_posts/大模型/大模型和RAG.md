---
title: 大模型基础应用框架
date: 2024-02-01 17:47:51
categories:
    - 大模型
tags:
---

## 前言

- 大模型应用面临的核心挑战包括以下三点：
    1. 模型缺乏零售领域的专业知识，建设业务专属大模型训练成本高
    2. 模型内容生产伴有幻觉，而检索海量业务信息又缺乏有效技术，检索成本高
    3. 在商家问答等多流程复杂业务场景下，模型缺乏自主规划能力，需要大量人工干预

- 为了应对上述三点挑战，一整套大语言模型应用解决方案：融合基于ReAct框架的AI Agent、SFT（指令微调）与RAG（检索增强生成）技术的应用框架，不仅赋予大模型学习领域知识的能力，还显著提升了模型的自主决策和信息处理精确度，为业务人员高效落地大模型的微调、部署和应用提供了落地保障。

![](/img/note/202403171020.png)


## 高效微调（SFT）

- 通用大模型虽然在处理通用知识方面表现出色，但缺乏针对零售垂直领域的知识理解。为此，需要引入经过人工标注的领域数据，对已完成预训练的通用大模型进行微调，从而得到具有该领域知识的零售垂域大模型。这个过程就是“有监督微调（Supervised Fine-Tuning）”，简称SFT。

### 流程介绍

1. 数据生产：创建用于微调预训练模型的高质量数据集，数据集质量对模型训练的效果至关重要。业务数据往往格式不统一、噪声多，如何以这些业务数据为基础，高效构建可用于微调训练的数据集，是数据生产环节的痛点。

2. 模型选型：根据对中文的支持程度、参数量级、性能等选择合适的预训练模型作为微调的起点。高速发展的开源社区为业务方提供了大量可供选择的预训练模型，但不同模型擅长不同任务，需要实验对比模型表现。而开源模型存在样本标注、模型标准不统一的问题，将开源方案应用在企业环境中也需要一定的适配工作量，给业务方带来了较高的模型选型成本。

3. 模型微调：使用准备好的数据集对选定的预训练模型进行微调。训练时需要设置适当的学习率、批次大小和训练周期等参数，同时监控模型的性能，如损失函数和准确率等指标。在算力资源紧缺的背景下，不少业务方面临算力资源不足的问题，如何用最小的算力资源实现最优的模型训练性能至关重要。

4. 效果验证：使用独立的验证数据集对模型进行测试，评估模型训练效果。关键是建立系统的模型评估指标，并选择合适的方法高效进行效果评估。

![](/img/note/202403171021.png)


## 检索增强生成（RAG）

- 大型语言模型通过监督式微调（SFT）补充了特定领域知识的不足，但在获取时效性知识、减少内容幻觉以及确保数据安全等方面依然存在挑战。在实际场景中，无论是来自C端用户的商品咨询，还是来自B端商家的平台规则咨询，对生成答案的时效性、专业度、准确性要求都更高，还需要大模型具备多轮对话的理解能力。

- 检索增强生成技术（Retrieval-Augmented Generation，简称RAG）的引入，有效减轻了这些问题。RAG的核心是根据用户提问（Query）从外部数据库检索相关信息，并基于此生成回答（Answer），相当于给大模型装上了“知识外挂”，基础大模型不用再训练即可随时调用特定领域知识。 这不仅提升了回答的时效性和准确性，还增加了答案的可解释性和可扩展性。此外，企业可以将数据库在本地维护，无需上传至开源模型，确保了数据安全性。

- 当用户询问“某两款不同品牌手机有什么不同时”时，RAG技术通过索引，为大模型“外挂”两款手机不同参数和属性数据、最新热门趋势等知识库，通过检索技术在商品知识库中找到准确的商品参数等信息，通过大模型生成能力对比两款手机在哪些重要维度有所不同，高效、精准地向用户输出两款手机差异性。

### 流程介绍

![](/img/note/202403171022.png)

![](/img/note/202403162111.png)

#### 检索数据增强阶段

- 构建用于检索的语料库的过程，包括“数据提取与处理—文本向量化—创建索引—导入向量数据库”几步。这一阶段的关键是如何通过各类技术，构建有效的语料库，以提供给模型用于生成文本的信息。

1. 知识库构建
    - 基于Data Warehouse构建知识库，通过增强数据粒度、对齐优化等优化策略增强知识库可用性。 增强数据粒度策略加强数据源可读性。通过推行数据标准化流程，去除无关信息、特殊字符、歧义及重复内容，对数据内容进行修订和简化，重点建设结构化知识索引，促进信息的高效检索与利用。对齐优化策略解决用户问题与文档内容不一致问题，引入假设性问题生成机制，针对语料库中每个文档设计相应的问题（Query）并嵌入文档中，提升用户问题/Query的召回率，有效解决了文档间的对齐挑战。

2. 数据索引优化
    - 数据索引优化旨在通过对索引结构优化和元数据信息整合等策略提升索引内容的质量，确保数据检索的效率和精度。 索引结构优化策略提升知识库内答案相关上下文被召回概率，通过块优化技术（Chunk optimization）调整切词大小和参数，最小化噪声数据的影响；还可以通过改变索引路径，并引入图结构信息来进一步优化索引结构。添加元数据信息策略提升检索相关性，特别是在处理时间敏感的数据如电子邮件查询时，强调最新信息的相关性而不仅是内容相似性。通过在索引块中嵌入关键元数据属性（如时间戳和章节编号等结构标识），进行精细化过滤，从而提升检索效率与相关度。

3. 优化Embedding模型
    - Embedding模型将用户查询（Query）和语料块（Doc）文本转换成为向量。通过选取动态Embedding（Dynamic Embedding）模型，并微调Embedding（Fine-tuning Embedding） ，优化Embedding效果，提高其精确度和适应性。

    - 通过选取动态Embedding模型，可将用户查询Query与知识库内容结合上下文内容转化为向量并进行匹配，提升匹配精准度。动态Embedding模型利用基于Transformer架构的深度学习模型、细粒度的语义捕获和多任务学习能力，根据对同一词汇的上下文理解，动态调整其向量表示，使得模型能够生成反映全局语义特征的向量，优化了词义多样性和歧义词汇的精准表征。为提升模型对垂域内容理解，可微调Embedding，通过对预训练Embedding模型（如BGE、Voyage等）进行微调训练，增强模型在垂直领域任务中的表现。包括针对特定领域微调，帮助模型捕捉到该领域的术语和微妙差异，以及针对具体的检索任务微调，使之精准匹配用户查询（Query）和相关文档块（Doc）。

4. 兼容向量数据库
    - 支持包含Vearch、Milvus、Pinecone等在内的多种向量数据库。


#### 检索过程增强阶段

- 根据用户查询（Query）在语料库中进行检索，召回相关信息，并通过LLM服务生成摘要内容的过程。检索环节中，通过文本检索与向量检索的方式计算问题与语料库内文档块之间相似度来，召回相似度最高的top K个文档块。为了提升检索的精度，往往会在首次召回后加上过滤（Filter）、排序（Rank）等环节。摘要生成环节中，结合prompt工程，利用大模型对用户问题与检索完成的答案进行总结，生成答案摘要。为提升结果准确度，大模型可根据问题范围提前进行SFT微调训练。

1. 查询（Query）改写
    - 通过知识推理、关键词识别、属性抽取等技术，深入理解用户查询（Query）意图，并通过查询改写（Query Rewrite）提高检索的相关性和精度。

2. 召回策略
    - 召回策略优化的目标包括准确率提升和性能提升两方面。准确率提升方面，我们采用多跳检索（Multi-hop Retrieval）和相关性召回策略，执行多次连续且逐渐深入的检索，以便从不同的数据源中获取更全面深刻的信息，从而提升召回的准确率；性能提升方面，引入检索结果缓存机制（Retrieval Cache）以优化系统性能，减少查询响应时间。

3. 过滤/排序（Filtering/Ranking）
    - 采用排序算法和过滤机制，根据用户行为和上下文信息对召回的文档进行精准排序，排除不相关或低质量的内容。

4. 摘要生成
    - 利用提示词工程（Prompt Engineering）技术，给用户提供相应的Prompt模板，优化文档摘要的自动生成结果；并通过模型微调（Fine-tuning）提升生成摘要的相关性和丰富度。

#### 效果增强阶段

1. 建立效果评估机制
    - 效果增强阶段旨在通过多轮评估，明确现有RAG方案的优化方向，优化最终生成效果。我们支持主观+客观相结合的评估方式，针对检索质量和生成质量分别建立相应的评估维度，使用多种主流评估框架对RAG效果进行评估。

2. 针对检索质量优化
    - 针对检索质量，采取检索策略选择与检索精度调优的双重途径。基于评估反馈，筛选与当前数据集和任务目标最匹配的检索策略，包括关键词匹配、语义搜索、图数据库检索等，并对检索参数进行精细调整，以优化检索结果的准确率和相关度。

3. 针对生成质量优化
    - 针对生成质量，进行模型微调和数据结构重组两方面优化。根据评估效果反馈，进一步微调Embedding模型和生成模型，精确适配特定语料库和任务。此外，优化的数据结构与处理流程，以提高模型的学习效率和生成质量。


## AI智能体（AI Agent）

![](/img/note/202403171023.png)

- AI Agent可以理解为：一个可以感知环境并能够基于当前场景做出决策的“智能体”。 当下大模型应用大多仅具备类似ChatGPT 的对话式能力，无法自主执行复杂任务。为了拓展大模型的能力，可以为其添加各类组件（如Planning/Proflie/Memory/Action等），实现复杂任务的拆解、规划和执行。AI Agent常见组件如下：
    1. Planning：将复杂的任务分解为更易处理的子任务，并制定出有效的策略。
    2. Proflie：描述了Agent的各种属性，如角色、目标、能力、知识和行为方式等。
    3. Memory：存储和组织从环境中获取的信息，以指导未来行动。
    4. Action：将抽象的决策转化为具体的行动。

- 就交互形式而言，基于大型语言模型的AI代理可以分为两大类：单一智能体（Single Agent）和多智能体系统（Multi-Agents）。
    1. 单一智能体（Single Agent）：在其运行环境中独立作用，专注于一个特定的任务或服务领域，能够接收人类以自然语言提出的指令，并基于这些指令执行一些简单的任务，如数据查询、日程管理等，扮演人类智能助手的角色。目前比较成熟的产品包括AutoGPT、BabyAGI等等。
    2. 多智能体（Multi-Agents）：涉及多个Agent协同工作，以解决单Agent难以独立处理的复杂问题。Agents们有不同的角色和专长，通过有效的协作共同实现目标。协作方式可以是合作型的，即通过共享信息、观点和资源来解决问题；也可以是对抗型的，比如通过竞争、谈判和辩论来优化决策过程，淘汰错误策略。这种多元化的互动模式使得多智能体系统能够应对更为复杂和动态的环境，展现出比单一智能体更加强大和灵活的问题解决能力。
