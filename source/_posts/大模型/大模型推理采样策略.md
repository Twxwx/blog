---
title: 大模型推理采样策略
date: 2024-06-30 21:41:44
categories:
    - 大模型
tags:
---

## 概述

- 进行不同的采样策略可以对生成文本的多样性和质量进行调控，以满足不同的需求和应用场景。通过选择不同的采样策略，可以平衡生成文本的多样性和质量。贪婪采样适用于需要高准确性的任务，而温度采样、Top-k 采样和Top-p 采样则可以在一定程度上增加生成文本的多样性，使得输出更加丰富和有趣。具体选择哪种采样策略取决于应用的需求和期望的输出效果。

## 大模型推理参数

- do_sample: 控制是否使用采样方法生成输出。当 do_sample=True 时，模型会根据词的概率分布进行随机采样。在每个时间步，下一个词的选择是基于其预测概率的随机过程。这增加了生成文本的多样性和创造性，因为即使概率较低的词也有机会被选中。为了控制这种随机性，通常还会配合使用其他参数；当 do_sample=False 时，模型会采用Greedy Search。

- temperature: 用来调节 softmax 函数的分布。在生成过程中，temperature 越高，模型的输出越随机；temperature 越低，模型的输出越确定。

- Top-p: 通过选择占总概率质量 p% 的最可能的词（或 token）进行采样。与 top-k 不同，top-p 动态地调整候选 token 的数量，确保这些 token 的累积概率超过阈值 p。例如，如果 p=0.9，模型会在概率分布的前 90% 的 token 中进行选择。Top-p 采样相比 Top-k 更加灵活，因为它根据概率分布的形状调整 token 的选择范围。

- Top-k: 在每个时间步选择概率最高的 k 个 token 进行采样。模型生成下一个 token 时，首先对所有可能的 token 进行排序，然后仅从前 k 个最有可能的 token 中进行选择。Top-k 使生成过程更具确定性，因为它限制了选择的范围。k 的值越大，生成的文本可能性越广，但也更随机；k 的值越小，生成的文本会更确定，但可能会缺乏多样性。

## 采样策略

### 贪心搜索（Greedy Search）

![](/img/note/202406302238.png)

### 集束搜索（Beam Search）

![](/img/note/202406302239.png)

![](/img/note/202406302240.png)

### Top-k Sampling

![](/img/note/202406302241.png)

### Top-p Sampling

![](/img/note/202406302242.png)

### Temperature

![](/img/note/202406302243.png)

### 联合采样（top-k & top-p & Temperature）

![](/img/note/202406302244.png)

1. 首先我们设置top-k=3，表示保留概率最高的3个token。这样就会保留女孩、鞋子、大象这3个token。
2. 接下来，我们可以使用top-p的方法，保留概率的累计和达到0.8的单词，也就是选取女孩和鞋子这两个token。接着我们使用 Temperature = 0.7 进行归一化
3. 接着，我们可以从上述分布中进行随机采样，选取一个单词作为最终的生成结果