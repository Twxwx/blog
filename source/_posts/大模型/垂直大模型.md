---
title: 垂直大模型
date: 2024-01-29 15:08:51
categories:
    - 大模型
tags:
---

## 引言
- 相比能做很多事，但每件事都马马虎虎的通用大模型；只能做一两件事，但这一两件事都能做好，可被信赖的垂直大模型会更有价值。这样的垂直大模型能帮助我们真正解决问题，提高生产效率。

## 垂直大模型基本套路

![](/img/note/202401291517.png)

- Continue PreTraining: 一般垂直大模型是基于通用大模型进行二次的开发。为了给模型注入领域知识，就需要用领域内的语料进行继续的预训练。
- SFT: 通过SFT可以激发大模型理解领域内的各种问题并进行回答的能力(在有召回知识的基础上)
- RLHF: 通过RLHF可以让大模型的回答对齐人们的偏好，比如行文的风格。
- 需要注意的是一般垂直领域大模型不会直接让模型生成答案，而是先检索相关的知识，然后基于召回的知识进行回答。这种方式能减少模型的幻觉，保证答案的时效性，还能快速干预模型对特定问题的答案。
- SFT和RLHF阶段主要要培养模型的三个能力:
    1. 领域内问题的判别能力，对领域外的问题需要能拒识
    2. 基于召回的知识回答问题的能力
    3. 领域内风格对齐的能力，例如什么问题要简短回答什么问题要翔实回答，以及措辞风格要与领域内的专业人士对齐

### 继续预训练

- 通过继续预训练能给通用的大模型注入领域知识，领域内的专业词能更充分的学习。这部分只需要准备领域内的语料即可，然后进行LLM任务的继续训练。
- 如果想要领域的模型还具备一定的通用能力，通用的能力不会退化（或者灾难性遗忘）这就需要在语言模型训练的时候混杂通用的数据。

### 领域微调数据构建

- 领域微调的核心是构建高质量大规模的领域微调数据。 让人去收集一个领域内的语料是容易的，但是让人去编写领域内的微调指令和回答是很难的。
- 下面的方法都是来尝试解决这个问题。这些方法的核心都是基于一些已有的数据 + GPT4，然后生成领域内的微调数据。
- 一条微调数据包括三个部分：指令，输入和输出

![](/img/note/202401291530.png)

#### Self-Instruct

![](/img/note/202401291533.png)

- 如果一个问题是“分类”问题，则采用“output-first”的生成方式，即首先生成输出（具体哪个类别），然后再根据指令和输出，生成输入。
- 如果一个问题是“生成”问题，则采用“input-first”的生成方式，即首先生成输入，然后再根据指令和输入，生成输出。

#### Self-QA

![](/img/note/202401291535.png)

- 基本的思想是：首先根据无结构的文档通过GPT4生成可能的指令，然后输入指令和对应的文档再让 GPT4 生成问题的答案。

#### Self-KG

![](/img/note/202401291541.png)

- 如果一个领域已经有了高质量的知识图谱，也可以直接基于知识图谱生成指令数据。

### 减缓幻觉

#### 输出引用

- 通过给大模型相关的知识进行参考，并且让模型在生成中附上引用的标注，能提升模型的回答质量，减少幻觉。
- 让模型输出引用还有一个好处：用户自己可以通过提供的参考快速判断回答对不对（参考不能太长）。这样即使回答错了，用户也能自己知道，相对可控。
- 分析表明回答的质量与召回文档的质量有很大关系，这部分还有很大的提升空间。

#### 事实一致性评估

- 我们也可以直接训练一个模型来做这样的判断。如果幻觉检测模型判断生成的内容与参考相矛盾，就可以在后处理的阶段对回答进行二次处理。

### 知识召回

- 为了减少回答的幻觉，保证时效性，会先召回相关的知识帮助模型进行回答。包括基于关键词的字面召回，基于相似度模型的语义召回等。但是实际落地就会发现召回的质量往往较差，下面介绍一些具体的优化方案。

#### Dense Passage Retrieval

![](/img/note/202401291554.png)

- 根据问题召回能回答问题的相关文档。如图所示，在DPR是一个双塔结构，会有两个独立的编码器分别对问题和文档进行编码。在训练的时候是一个对比学习的loss，即让不相关文档的点积近可能为0，相关文章的点积近可能为1。

#### Generalizable T5-based dense Retrievers

- 直接采用T5对问题和文章进行编码，同样也是对比学习的loss。需要注意的是这里问题和文章是同一个编码器。进一步分析可以发现，随着模型尺寸的增大效果也会越来越好，这种方法也优于DPR。当然因为参数量更大了，推理速度也要比DPR更慢。

#### Keyword LLM

![](/img/note/202401291835.png)

- 在专业的垂直领域，待检索的文档都是非常专业的表述，而用户的问题往往是非常不专业的白话表达。所以直接拿用户的query去检索，召回的效果就会比较差。Keyword LLM就是解决这其中GAP的。会先让大模型基于用户的query生成一系列的关键词，然后再用关键词去知识库中做检索。

## 待解决问题

- 如何拒识领域外的问题？如果不能回答，如何优雅的失败？
- 当前是基于文档的来生成答案，答案中很多内容都是从文档中直接COPY，能否对这种COPY的生成进行加速？
- 领域内一般有自己专业的工具，例如制造业中的工程计算软件，大模型如何与这些工具打通？
- 如果一句话中有多个问题要怎么召回？例如：”自闭症有哪些症状？跟遗传有关吗？能被治愈吗？”
- 大模型确实容易产生幻觉，但是如果“幻觉”出来的内容是对的，就会很惊喜，我们更愿意称之为模型的“泛化”能力。如果一味减缓幻觉是不是也会让模型丧失泛化的能力？




